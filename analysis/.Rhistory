}
pruning2<-function()
{
graph <- graph.adjacency(pruned1,weighted=TRUE,mode="undirected",diag=FALSE)
for (i in 1:ncol(data_matrix))
{
for (j in 1:ncol(data_matrix))
{
if (pruned1[i,j]!=0){
if (length(all_simple_paths(graph,i,j))==1)
pruned1[i,j]=0;}
}
}
pruned2<<-matrix(pruned1,nrow = ncol(data_matrix),ncol=ncol(data_matrix))
return("Prune2 DONE");
}
megiiing<-function()
{
for (i in 1:ncol(data_matrix))
{
for (j in 1:ncol(data_matrix))
{
}
}
}
key_term_R1<-function()
{
R1 <<- array(0,dim=c(11));
for (i in 2:(ncol(data_matrix))){
for (j in 1:i-1){
relation_matrix[i,j]<-relation_matrix[j,i];}}
graph <- graph.adjacency(pruned2,weighted=TRUE,mode="undirected",diag=FALSE);
cluster<-clusters(graph,mode="strong");
for (i in 1:ncol(data_matrix))
{
for (j in 1:ncol(data_matrix))
{
if (cluster$membership[i]!=cluster$membership[j])
R1[i]<<-R1[i]+relation_matrix[i,j];
}
}
return("key_term extraction DONE");
}
key_term_R2<-function()
{
R2 <<- array(0,dim=c(11));
ci<-0;
for (i in 2:(ncol(data_matrix))){
for (j in 1:i-1){
relation_matrix[i,j]<-relation_matrix[j,i];}}
graph <- graph.adjacency(pruned2,weighted=TRUE,mode="undirected",diag=FALSE);
cluster<-clusters(graph,mode="strong");
for (i in 1:ncol(data_matrix))
{
for (j in 1:ncol(data_matrix))
{
if (cluster$membership[i]!=cluster$membership[j])
{
ci<-cluster$membership[j];
si<-0;
nprimt<-0;
for (t in 1:ncol(data_matrix) )
{
if (cluster$membership[t]==ci)
{
si<-si+co_occurrence[i,t];
nprimt<-nprimt+co_occurrence[t,t];
}
}
pttt<-0;
for (t in 1:ncol(data_matrix) )
{
if (cluster$membership[t]==ci)
{
pttt<-co_occurrence[t,t]/nprimt;
R2[i]<<-R2[i]+(((co_occurrence[i,t]-(si*pttt))^2)/(si*pttt));
}
}
}
if (R2[i]!=0 | is.nan(R2[i])){
break}
}
}
return("key_term extraction2 DONE");
}
relation()
View(relation_matrix)
isSymmetric(relation_matrix)
pruning1(1)
View(pruned1)
pruning2()
library("igraph", lib.loc="~/R/win-library/3.3")
pruning2()
View(pruned2)
data("cars")
View(cars)
rm(cars)
library(MASS)
data("Cars93")
view(Cars93)
View(Cars93)
which(Cars93,Cars93$Cylinders==5)
Cars93(which(Cars93,Cars93$Cylinders==5))
Cars93[Cars93$Cylinders==5]
Cars93[Cars93$Cylinders=5]
Cars93[Cars93$Cylinders=='5']
Cars93[which(Cars93$Cylinders==5)]
Cars93[Cylinders=='5']
Cars93[(Cars93$Cylinders==5, ]
Cars93[(Cars93$Cylinders==5 ]
Cars93[(Cars93$Cylinders==5) ]
Cars93[(Cars93$Cylinders==5), ]
Cars93[(Cars93$Cylinders==5),1 ]
df=Cars93[(Cars93$Cylinders==5), ]
view(df)
View(df)
df$Manufacturer
Cars93$Manufacturer
q()
result <- read.csv(file="x.csv",header=TRUE,sep=",");
View(result)
actual=result$truth
predicted=result$predicted
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="x.csv",header=TRUE,sep=",");
actual=result$truth
predicted=result$predicted
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="1.csv",header=TRUE,sep=",");
actual=result$truth
predicted=result$predicted
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="2.csv",header=TRUE,sep=",");
actual=result$truth
predicted=result$predicted
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="3.csv",header=TRUE,sep=",");
actual=result$truth
predicted=result$predicted
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="1.csv",header=TRUE,sep=",");
actual=result$X1
predicted=result$X2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="1.csv",header=False,sep=",");
result <- read.csv(file="1.csv",header=FALSE,sep=",");
actual=result$V1
predicted=result$V2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="2.csv",header=FALSE,sep=",");
actual=result$V1
predicted=result$V2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="3.csv",header=FALSE,sep=",");
actual=result$V1
predicted=result$V2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="4.csv",header=FALSE,sep=",");
actual=result$V1
predicted=result$V2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="5.csv",header=FALSE,sep=",");
actual=result$V1
predicted=result$V2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="6.csv",header=FALSE,sep=",");
actual=result$V1
predicted=result$V2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
View(result)
result <- read.csv(file="6.csv",header=FALSE,sep=",");
View(result)
actual=result$V1
predicted=result$V2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
result <- read.csv(file="1.csv",header=FASLE,sep=",");
setwd("~/")
result <- read.csv(file="1.csv",header=FASLE,sep=",");
result <- read.csv(file="1.csv",header=FALSE,sep=",");
View(result)
actual=result$V1
predicted=result$V2
cm = as.matrix(table(Actual = actual, Predicted = predicted))
cm
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
diag
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
accuracy
precision = diag / colsums
recall = diag / rowsums
f1 = 2 * precision * recall / (precision + recall)
data.frame(precision, recall, f1)
macroPrecision = mean(precision)
macroRecall = mean(recall)
macroF1 = mean(f1)
data.frame(macroPrecision, macroRecall, macroF1)
install.packages("precrec")
data(P10N10)
library(precrec)
data(P10N10)
load(P10N10)
P10N10$labels
P10N10$scores
scores = P10N10$scores, labels = P10N10$labels
scores = P10N10$scores labels = P10N10$labels
scores = P10N10$scores
labels = P10N10$labels
sscurves <- evalmod(scores = P10N10$scores, labels = P10N10$labels)
sscurves$prcs
autoplot(sscurves)
library(ggplot2)
# Show ROC and Precision-Recall plots
autoplot(sscurves)
library("e1071")
attach(iris)
alldata <- subset(iris, select=-Species)
label <- Species
label
set.seed(20)
irisCluster <- kmeans(x, 3, nstart = 20)
set.seed(20)
irisCluster <- kmeans(alldata, 3, nstart = 20)
irisCluster
irisCluster$cluster
table(irisCluster$cluster, iris$Species)
sscurves <- evalmod(scores = y, labels = irisCluster$cluster)
sscurves <- evalmod(scores = label, labels = irisCluster$cluster)
label
P10N10$scores
table(irisCluster$cluster, iris$Species)
library (ROCR);
pred <- prediction(irisCluster$cluster, label);
library(caret)
precision <- posPredValue(irisCluster$cluster,label)
irisCluster$cluster
ourpridict<-irisCluster$cluster
label
ourpridict
table(ourpridict, label)
mypre=c(1,1,1,2,2,2)
label=c(1,2,2,3,3,3)
table(mypre, label)
source("inference.R")
install.packages("inference.R")
install.packages("inference.r")
load("D:/Master/SI/Project - Phase 1/sample_khanevar.Rdata")
metraj=sample_khanevar[38]
View(metraj)
metraj=subset(metraj,is.na(metraj$Col55_9Met)==0)
hist(metraj)
hist(metraj$Col55_9Met)
hist(metraj$Col55_9Met)
metraj$Col55_9Met <- as.numeric(as.character(metraj$Col55_9Met))
hist(metraj$Col55_9Met)
p_value=2*pnorm(((metraj_mean-700)/(sd(metraj$Col55_9Met)/sqrt(259))),lower.tail = FALSE)
metraj_mean=mean(metraj$Col55_9Met)
View(sample_khanevar)
install.packages("ggplot2")
library("ggplot2", lib.loc="~/R/win-library/3.3")
library("ggplot2", lib.loc="~/R/win-library/3.3")
ggplot(diamonds, aes(carat)) +
geom_histogram()
ggplot(diamonds, aes(carat)) +
geom_histogram(binwidth = 0.01)
ggplot(diamonds, aes(price, fill = cut)) +
geom_histogram(binwidth = 500)
setwd("C:/Users/Mostafa/Desktop/analysis")
library(readr)
tag_computable_p2new <- read_csv("C:/Users/Mostafa/Desktop/analysis/tag-computable-p2new.csv")
View(tag_computable_p2new)
View(tag_computable_p2new)
twotag = subset(tag_computable_p2new,tag_computable_p2new$tag=='old' & tag_computable_p2new$tag=='new')
twotag = subset(tag_computable_p2new,tag_computable_p2new$tag=='old' and tag_computable_p2new$tag=='new')
twotag = subset(tag_computable_p2new,tag_computable_p2new$tag=='old' && tag_computable_p2new$tag=='new')
twotag = subset(tag_computable_p2new,tag_computable_p2new$tag=="old" & tag_computable_p2new$tag=="new")
twotag = subset(tag_computable_p2new,tag_computable_p2new$tag=="old" | tag_computable_p2new$tag=="new")
View(twotag)
write.table(twoTag, file = "maxDocID.csv",sep = ",")
write.table(twotag, file = "maxDocID.csv",sep = ",")
library(readr)
tag_computable_p2new <- read_csv("C:/Users/Mostafa/Desktop/analysis/tag-computable-p2new.csv")
View(tag_computable_p2new)
twotag = subset(tag_computable_p2new,tag_computable_p2new$tag=="old" | tag_computable_p2new$tag=="new")
View(twotag)
write.table(twotag, file = "maxDocID.csv",sep = ",")
