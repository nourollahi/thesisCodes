<!-- $Id: DetectionScore.htm,v 1.2 2001/10/22 13:38:05 jon Exp $ -->
<HTML>
<HEAD>
<CENTER><TITLE>DetectionScore.pl User Manual</TITLE></CENTER>
<A NAME="DetectionScore.pl"> <B><BIG><CENTER>DetectionScore.pl User Manual</CENTER></BIG></B></A>

<BR>
<CENTER> <H1> The Generic Detection Task Scorer </H1> </CENTER>

</HEAD>

<BODY><p><hr>


<H1>Usage:</H1>
<DIR>
DetectionScore.pl <A HREF="DetectionScore.htm#key_format">-K key_file</A> <A HREF="DetectionScore.htm#options">&lt;Options&gt;</a> <A HREF="DetectionScore.htm#out_format">DetectionOutput</a>

</DIR>

<P>The 'DetectionScore.pl' program will score the output generated by an automatic detection system. 
The program assumes the following about the performed detection task:
<ul> <li> The systems is presented with two objects to compare, common examples are documents or speech waveforms.
     <li> The system makes a decision, either YES or NO.  The decision is YES if the two objects are considered 'equivalent',
     and 'NO' otherwise.
     <li> The system outputs a "score" indicating the degree to which the system believes the two objects are equivalent.
     High scores indicate strong belief, low scores indicate weak belief.
</UL>
     
Since many detection applications fit these general contraints, this
program will score the detection performance for a variety of
detection tasks.  

<P>The program requires two inputs, a <A
HREF="DetectionScore.htm#key_format">answer key file</A> (via the -K option), and a <A
HREF="DetectionScore.htm#out_format">detection system output
file</A>. The answer key file defines the compared objects and whether or not
the two objects are presumed equivalent.  The system output file records the 
system's decision and scores for the decisions.  

<P> The program computes a variety of performance statistics, and then
generates a scoring report and optionally Decision Error Tradeoff
(DET) graphs.

<h2> Detection Performance Assessment </h2>

<P> Detection performance is characterized in terms of the probability
of miss and false alarm errors (P<sub>miss</sub> and P<sub>fa</sub>).
The error probabilities are then combined into a single detection
cost C<sub>det</sub>, by assigning costs to miss and false alarm
errors:

<DIR>
C<sub>det</sub> = C<sub>miss</sub> * P<sub>miss</sub> * P<sub>target</sub> + C<sub>fa</sub> * P<sub>fa</sub> * (1-P<sub>target</sub>)
<dir>
where
<dir>
<UL>
<LI> C<sub>miss</sub> and C<sub>fa</sub> are the cost of a Miss and False Alarm respectively,
<LI> P<sub>miss</sub> and P<sub>fa</sub> are the conditional probabilities of a Miss and False Alarm respectively, and
<LI> P<sub>target</sub> are the <i>a priori</i> target probabilities.
</DIR>
</DIR>
</DIR>
</DIR>

C<sub>det</sub> is the bottom-line representation of detection performance that is
used to judge systems.  Unfortunately, the value of C<sub>det</sub>  is also a
function of application parameters.  Specifically, C<sub>det</sub>  is a function of
the costs of detection errors and a priori target probabilities.
Because of this, and in order to provide a more intuitively meaningful
measure of system performance, C<sub>det</sub> will be normalized so that
(C<sub>det</sub>)<sub>norm</sub> can be no less than one without extracting information from
the source data.  This is done as follows:

<dir>
(C<sub>det</sub>)<sub>norm</sub> = C<sub>det</sub> / MIN( C<sub>miss</sub> * P<sub>target</sub>, C<sub>fa</sub> * (1-P<sub>target</sub>))
</dir>

Thus the absolute value of (C<sub>det</sub>)<sub>norm</sub> is a direct measure of the value of the system.

<P> Using these formulas, performance is measures in two ways,
<b>decision weighted</b> or <b>block weighted</b>.  Decision weighted
performance, (sometimes called pooled or macro performance), weights
each decision equally.  These are global performance statistics, but
no mean or variance can be associated with the performance
variability.  Block weighted performance computes decision weighted
performance statistics on subsets, or blocks, of the test set, and
then reports the mean of those statistics.  The advantage of block
weighted statistics is it has a reduced variance.  The subsets can be,
and often are, non-uniform in size.

<A name="options"><P> The following &lt;Options&gt; are recognized by the program:</A>

<DIR>
<TABLE BORDER=2> 
<TR> <TD> -C C<sub>miss</sub>:C<sub>fa</sub> <TD> -> <TD> Set the cost of a missed detection and the cost of a
	false alarm to 'C<sub>miss</sub>' and 'C<sub>fa</sub>' respectively.  These numbers are used in the 
	detection cost function.  Default values are C<sub>miss</sub>=1.0 and C<sub>fa</sub>=0.1 ;
<TR> <TD> -D Detail <TD> -> <TD> Write internally organize evaluation corpus and pertinent 
			statistics for debugging purposes.  This report, though voluminous, is
			intended to help researchers debug their internal versions of
			evaluation code.
<TR> <TD> -N TaskID,BlockID,DecisionID <TD> -> <TD>
                   Define the names used in the reports.  'TaskID' is the detection
                   task name, 'Link' is the default.  'BlockID' is the name that
                   describes the block divisions, 'Topic' is the default.  'DecisionID'
                   describes what individual decisions are made on, 'Story' is the
                   default.
<TR> <TD> -P P<sub>target</sub> <TD> -> <TD> Use P<sub>target</sub> for the detection cost functions.
<TR> <TD> -r Report <TD> -> <TD> Write the summary report to 'Report' rather than STDOUT, the default.
<TR> <TD> -S <TD> -> <TD> If this flag is used, system output entries not present in the key file are ignored during scoring.
<TR> <TD> -v num <TD> -> <TD> Set the verbose level to 'num'. Default 1.<BR>
	                   ==0 None, ==1 Normal, >5 Slight, >10 way too much, >15 not even funny

<TR> <TD COLSPAN=3> <b><center>Options that apply to the DET plots:</center></b>
<TR> <TD> -d DETfile <TD> -> <TD> Create a DET plot in GNUplot format with the file
	root 'DETfile'.  The program makes several files each with additional extensions.
	The file 'DETfile'.plt is a command file for GNUplot and can be printed using the
	command "gnuplot 'DETfile'.plt | lpr". 
<TR> <TD> -t title <TD> -> <TD> Set the title line for the plot to 'title'.
<TR> <TD> -p       <TD> -> <TD> Produce a single story-weighted DET line trace.
<TR> <TD> -w       <TD> -> <TD> Produce a single topic-weighted DET line trace.  This is the default option.
<TR> <TD> -n       <TD> -> <TD> Add 90% confidence intervals to the topic-weighted DET graph.
<TR> <TD> -Z uncompress <TD> -> <TD> Specify the command for uncompressing the system output files prior to 
                          scoring.  The decompression applies to ONLY the system decision files, not the file lists.  
			  The command is executed by opening a pipe command if the system output file
			  ends with a .Z or .gz suffix.  The command is required to read a compressed stream from 
			  STDIN, and write the uncompressed stream to STDOUT.
</TABLE>
</DIR>



<h1> Program Input </h1>

<A NAME="key_format"> <H2> Answer key file format </H2> </A>

The answer key file defines the presumed correct answers for all of the detection object pairs.  The file consists of  a header record, followed a data record for each detection object pair.  With the exception of the header record, any text following a '#' is ignored.

<P> The BNF structure of the key file is:
	
<DIR>
	&lt;HEADER_LINE&gt; <BR>
	&lt;DETECTION_OBJECT&gt;	<BR>
	&lt;DETECTION_OBJECT&gt;	<BR>
	...
	<P>	

Where:
	<DIR>
	<TABLE BORDER=2>
	<TR> <TD> &lt;HEADER_LINE&gt;   <TD> :== <TD> <B>  # LINK_DETECTION </B> <BR> 'LINK_DETECTION' is the expected value.  However, if another symbol is used, an ignorable warning message will be generated.
	<TR> <TD> &lt;DETECTION_OBJECT&gt; <TD> :== <TD> <B> &lt;OBJECT&gt; &lt;OBJECT&gt; &lt;TRUTH&gt; &lt;BLOCKID&gt; </B> <BR>
	<TR> <TD> <DIR>  &lt;OBJECT&gt; </DIR>  <TD> :== <TD> <B> STRING </b> <BR> A text string identifying the object to be compared.  The program does not derive any meaning from this string, except to cross reference the key entries to the system output.
	<TR> <TD> <DIR>  &lt;TRUTH&gt; </DIR>  <TD> :== <TD> <B> TARGET | NONTARGET </b> <BR> Specify whether or not the two objects are equivalent, a 'TARGET', or not a 'NONTARGET'.
	<TR> <TD> <DIR>  &lt;BLOCK&gt; </DIR>  <TD> :== <TD> <B> STRING </b> <BR> Specify which 'block' this detection pair belongs to.  The STRING will be sorted numerically in the reports, so care should be taken to choose appropriate strings.  If your detection evaluation does not support the notion, specify an identical value for all pairs.
	</TABLE>
	</DIR>

</DIR>

The following is an excerpt from a detection answer key file.

<DIR>
<pre>
# LINK_DETECTION
#
# Record format : '<FILE_1>:<DOCNO_1> <FILE_2>:<DOCNO_2> TARGET|NONTARGET <TOPICID>'
#
APW19980104.0002 NYT19980104.0098 NONTARGET 44
APW19980104.0012 NYT19980105.0840 NONTARGET 33
</PRE>
</DIR>

<A NAME="out_format"><H2> Detection System Output Format </H2></A>

The detection systems must output an answer line matching each line in
the key file.  The first record in this file will contain two fields
which specify information that applies globally to the whole file.

Comment lines begin with the '#' character, and any text following a
'#' is ignored.  The exception to this rule is the first comment line
can optionally contain a long description of the system under test.  This
description will be included in the scoring report along side the
&lt;SYSTEM&gt; value described below.  After the initial comment line,
blank lines are treated as comments.

<P> The BNF structure of the detection system output file is:
	
<DIR>
	&lt;SYSTEM&gt; &lt;DEF_PERIOD&gt; <BR>
	&lt;DECISION_LINE&gt; <BR>
	&lt;DECISION_LINE&gt; <BR>
	...
	<P>	

Where:
	<DIR>
	<TABLE BORDER=2>
	<TR> <TD> &lt;SYSTEM&gt; <TD> :== <TD> System is an alphanumeric
			character string that uniquely identifies the
			system being tested. (E.g., CDM_P05-8.v37)
	<TR> <TD> &lt;DEF_PERIOD&gt;   <TD> :== <TD> The deferral period before
						before decisions are made.
						This field exists in support of the TDT3
						evaluation.  It must not be omitted, 
						however the program will issue a 
						warning about non-standard deferral values.

	<TR> <TD> &lt;DECISION_LINE&gt; <TD> :== <TD>
			<B> &lt;OBJECT&gt; &lt;OBJECT&gt; &lt;DECISION&gt;	&lt;SCORE&gt; </B>
	<TR> <TD> <DIR> &lt;OBJECT&gt; </DIR>  <TD> :== <TD> <B> STRING </b> <BR> A text string identifying the object to be compared.  The program does not derive any meaning from this string, except to cross reference the key entries to the system output.

	<TR> <TD> <DIR> &lt;DECISION&gt; </DIR> <TD> :== <TD> <b> YES | NO </B> <br>
	                The decision is YES if the system believes that the
			to objects are equivalent, and NO otherwise.
	<TR> <TD> <DIR> &lt;SCORE&gt; </DIR> <TD> :== <TD> <b> NUMBER </B> <br>
	                A real number which indicates how
			confident the system is that the two objects are equivalent.
			High scores indicate strong belief, low scores indicate weak belief.

	</TABLE>
	</DIR>


</DIR>
	
The following is an excerpt from a detection system output file.

<DIR>
<PRE>
# Artificial sld results, Errors,
Errors 10
APW19980104.0002 NYT19980104.0098 YES 0.00609613178059631
APW19980104.0017 VOA19980106.2100.0060 YES 0.999469214386953
APW19980104.0017 NYT19980107.0513 YES 0.7777613437
</PRE>
</DIR>

<A name="report"><H2> Example Output Report </H2></A>

<DIR>
<PRE>
-------------------------------------------------------------------------------
------------------  Detection Task Performance Report  ------------------

Command line:   /data/data2/TDT99/Software/.....
Execution Date: Fri Aug  6 11:13:14 EDT 1999

Story Weighted Story Link Detection:     P(Miss)           = 0.0730
                                         P(Fa)             = 0.0094
                                         CLink             = 0.0024
                                         Norm(CLink)       = 0.1191

Topic Weighted Story Link Detection:     P(Miss)           = 0.4311
                                         P(Fa)             = 0.0098
                                         CLink             = 0.0096
                                         Norm(CLink)   *   = 0.4793

  *   Primary Evaluation Metric

DET Graph Minimum Detection Cost Analysis:
     Story Weighted Minimum CLink = 0.0183 at P(Miss) = 0.8102 and P(Fa) = 0.0216
     Topic Weighted Minimum CLink = 0.0190 at P(Miss) = 0.9228 and P(Fa) = 0.0055

                   | # Corr  # Miss  # Corr    # Fa      ||                           | Norm   
   Topic           | Link    Link    ! Link    ! Link    || P(Miss)  P(Fa)   CLink    | CLink  
   -----           | ------  ------  --------  --------  || -------  -----   -------  | -------
   1               |   59       1      59         1      || 0.0167   0.0167  0.0020   | 0.0983 
   7               |   11       1     107         1      || 0.0833   0.0093  0.0026   | 0.1287 
   13              |    9       1     109         1      || 0.1000   0.0091  0.0029   | 0.1445 
   15              |    0       1     118         1      || 1.0000   0.0084  0.0208   | 1.0412 
   23              |   11       1     107         1      || 0.0833   0.0093  0.0026   | 0.1287 
   32              |    0       1     118         1      || 1.0000   0.0084  0.0208   | 1.0412 
   33              |    1       1     117         1      || 0.5000   0.0085  0.0108   | 0.5415 
   37              |    1       1     117         1      || 0.5000   0.0085  0.0108   | 0.5415 
   44              |    0       1     118         1      || 1.0000   0.0084  0.0208   | 1.0412 
   77              |   35       1      83         1      || 0.0278   0.0119  0.0017   | 0.0861 
   -----           | ------  ------  --------  --------  || -------  -----   -------  | -------
   Sums            |  127      10    1053        10      ||                           |        
   Story Weighted  |                                     || 0.0730   0.0094  0.0024   | 0.1191 
   Topic Weighted  |                                     || 0.4311   0.0098  0.0096   | 0.4793 


Key File:                ../indexes_small/sld_SRC=nwt+bnasr_TEST:SL=eng,CL=nat.key
System Output File:      sld_SRC=nwt+bnasr_TEST:SL=eng,CL=nat.sld
Cost Function Parameters:
              Ptarget  = 0.02
              Cmiss    = 1
              Cfa      = 0.1

Detection Performance Calculations:
    System Identifier:   Errors   Description: 'Artificial sld results, Errors,'
    Deferral Period:     10

</PRE>
</DIR>

</BODY>
</HTML>
